{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import re\n",
    "import json\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test api connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"TOGETHER_API_KEY\"):\n",
    "    os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass(\"Enter API key for Together AI: \")\n",
    "\n",
    "# meta-llama/Llama-3.3-70B-Instruct-Turbo-Free   inputs` tokens + `max_new_tokens` must be <= 8193\n",
    "# Qwen/Qwen2.5-Coder-32B-Instruct                inputs` tokens + `max_new_tokens` must be <= 32769\n",
    "# meta-llama/Llama-3.2-3B-Instruct-Turbo         gives extra text\n",
    "model = init_chat_model(\"Qwen/Qwen2.5-Coder-32B-Instruct\", model_provider=\"together\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 22, 'total_tokens': 26, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen2.5-Coder-32B-Instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c91604df-e296-4798-b0d3-ce30bffe6a03-0', usage_metadata={'input_tokens': 22, 'output_tokens': 4, 'total_tokens': 26, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\")\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_for_llm(url):\n",
    "    response = requests.get(url)  \n",
    "    if response.status_code != 200:\n",
    "        return f\"Failed to retrieve content: {response.status_code}\"\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
    "        comment.extract()\n",
    "    for element in soup.find_all(['script', 'style', 'noscript', 'iframe', 'svg', 'canvas']):\n",
    "        element.extract()\n",
    "    for element in soup.find_all(style=True):\n",
    "        if any(pattern in element.get('style').lower() for pattern in [\"display:none\", \"display: none\", \"visibility:hidden\", \"visibility: hidden\"]):\n",
    "            element.extract()\n",
    "    for element in soup.find_all(class_=True):\n",
    "        classes = element.get('class')\n",
    "        if any(cls in str(classes).lower() for cls in [\"hidden\", \"d-none\", \"hide\", \"invisible\", \"visually-hidden\"]):\n",
    "            element.extract()\n",
    "    if soup.head:\n",
    "        for tag in soup.head.find_all(['meta', 'link']):\n",
    "            tag.extract()\n",
    "    content_str = str(soup.body) if soup.body else str(soup)\n",
    "    content_str = re.sub(r'\\n\\s*\\n', '\\n', content_str)\n",
    "    content_str = re.sub(r'^\\s+|\\s+$', '', content_str, flags=re.MULTILINE)\n",
    "    content_str = re.sub(r' {2,}', ' ', content_str)\n",
    "    content_str = re.sub(r' data-[^=]*=\"[^\"]*\"', '', content_str)\n",
    "    content_str = re.sub(r' class=\"[^\"]*\"', '', content_str)\n",
    "    content_str = re.sub(r' id=\"[^\"]*\"', '', content_str)\n",
    "    content_str = re.sub(r' style=\"[^\"]*\"', '', content_str)\n",
    "    for _ in range(3):\n",
    "        content_str = re.sub(r'<([a-z0-9]+)>\\s*</\\1>', '', content_str, flags=re.IGNORECASE)\n",
    "    return content_str\n",
    "\n",
    "def extract_pure_json(text: str) -> str:\n",
    "    \"\"\"Extract JSON content from text that might be wrapped in markdown code blocks.\"\"\"\n",
    "    import re\n",
    "    json_pattern = r\"```(?:json)?\\s*([\\s\\S]*?)```\"\n",
    "    match = re.search(json_pattern, text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return text.strip()\n",
    "\n",
    "def is_json_complete(text: str) -> bool:\n",
    "    try:\n",
    "        json.loads(text)\n",
    "        return True\n",
    "    except json.JSONDecodeError:\n",
    "        return False\n",
    "    \n",
    "def extract_links_from_page(html_content, base_url):\n",
    "    \"\"\"Extract all links from a page with their text\"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    links = []\n",
    "    \n",
    "    for link in soup.find_all('a', href=True):\n",
    "        href = link.get('href')\n",
    "        if href.startswith('#') or href.startswith('javascript:'):\n",
    "            continue\n",
    "            \n",
    "        text = link.text.strip()\n",
    "        full_url = urljoin(base_url, href)\n",
    "        links.append({\"url\": full_url, \"text\": text})\n",
    "    \n",
    "    return links\n",
    "\n",
    "def parse_repertoires_from_page(html_content: str, model) -> list[dict]:\n",
    "    \"\"\"Parse the given HTML and return a JSON list of repertoire items found on the page.\"\"\"\n",
    "    system_message = \"\"\"\n",
    "        I will provide you with an HTML snippet containing information about theater performances. Extract all performances, including their titles, dates, and times, and return the result as a JSON array with the following format:\n",
    "        ```\n",
    "        [\n",
    "        {\n",
    "            \"title\": \"Performance name\",\n",
    "            \"date\": \"YYYY-MM-DD\",\n",
    "            \"time\": \"HH:MM\",\n",
    "            \"status\": \"Performance status\",\n",
    "            \"place\": \"Performance place\",\n",
    "        }\n",
    "        ]\n",
    "        ```\n",
    "        Do not include any extra text in the response—only return valid JSON.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "    SystemMessage(system_message),\n",
    "    HumanMessage(html_content)\n",
    "    ]\n",
    "\n",
    "    full_response = \"\"\n",
    "    max_loops = 5\n",
    "    loop_count = 0\n",
    "\n",
    "    while loop_count < max_loops:\n",
    "        response = model.invoke(messages)\n",
    "        full_response += extract_pure_json(response.content)\n",
    "        if is_json_complete(full_response):\n",
    "            break\n",
    "\n",
    "        print(f\"⚠️ Detected incomplete JSON... requesting continuation (attempt {loop_count + 1})\")\n",
    "\n",
    "        messages.append(AIMessage(response.content))\n",
    "        messages.append(HumanMessage(\"Please continue from where you left off. Only continue the JSON.\"))\n",
    "        loop_count += 1\n",
    "    \n",
    "    return full_response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_page_and_get_repertoire_links(page_text, links, model):\n",
    "    \"\"\"\n",
    "    Ask the LLM to identify if this is a repertoire page and/or suggest links to repertoire pages\n",
    "    \"\"\"\n",
    "    links_text = \"\\n\".join([f\"{i+1}. {link['text']} - {link['url']}\" for i, link in enumerate(links[:30])])\n",
    "    prompt = f\"\"\"\n",
    "    Analyze theater website page and determine:\n",
    "\n",
    "    1. Is this a repertoire/program page that lists upcoming performances? (Yes/No)\n",
    "    2. If this is NOT a repertoire page, which of these links is most likely to lead to a page with the theater's repertoire/program/schedule of performances?\n",
    "\n",
    "    Respond with JSON in this format:\n",
    "    {{\n",
    "        \"is_repertoire_page\": true/false,\n",
    "        \"recommended_links\": [\n",
    "            {{\n",
    "                \"url\": \"https://example.com/link\",\n",
    "                \"confidence\": 0.9  // A score between 0-1 indicating confidence this link leads to repertoire\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    Only include links with confidence > 0.5. Sort by confidence descending.\n",
    "    \"\"\"\n",
    "    human_message = f\"\"\"\n",
    "    Page content excerpt:\n",
    "    {page_text}\n",
    "\n",
    "    Available links on the page:\n",
    "    {links_text}\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(prompt),\n",
    "        HumanMessage(human_message)\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    try:\n",
    "        response_content = response.content\n",
    "        json_match = re.search(r'({[\\s\\S]*})', response_content)\n",
    "        if json_match:\n",
    "            response_json = json.loads(json_match.group(1))\n",
    "        else:\n",
    "            response_json = json.loads(response_content)\n",
    "        return response_json\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing LLM response: {e}\")\n",
    "        return {\n",
    "            \"is_repertoire_page\": False,\n",
    "            \"recommended_links\": []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned HTML content saved to 'cleaned_repertoire.html'\n",
      "Original size: 403735 characters\n",
      "Cleaned size: 46764 characters\n",
      "Size reduction: 88.42%\n"
     ]
    }
   ],
   "source": [
    "url = \"https://teatrdramatyczny.pl/whats-on\"\n",
    "cleaned_html = clean_html_for_llm(url)\n",
    "with open(\"temp/cleaned_repertoire.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(cleaned_html)\n",
    "print(\"Cleaned HTML content saved to 'cleaned_repertoire.html'\")\n",
    "original_size = len(requests.get(url).text)\n",
    "cleaned_size = len(cleaned_html)\n",
    "reduction = (1 - cleaned_size/original_size) * 100\n",
    "print(f\"Original size: {original_size} characters\")\n",
    "print(f\"Cleaned size: {cleaned_size} characters\")\n",
    "print(f\"Size reduction: {reduction:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse HTML with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Detected incomplete JSON... requesting continuation (attempt 1)\n"
     ]
    }
   ],
   "source": [
    "with open(\"temp/cleaned_repertoire.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "full_response = parse_repertoires_from_page(html_content, model)\n",
    "\n",
    "with open(\"temp/llm_response.json\", \"w\") as file:\n",
    "    file.write(full_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching repertoire page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://teatrdramatyczny.pl/\"\n",
    "content = clean_html_for_llm(url)\n",
    "links = extract_links_from_page(content, url)\n",
    "is_repertoire_page = identify_page_and_get_repertoire_links(content, links, model)\n",
    "# repertoires = parse_repertoires_from_page(content, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_repertoire_page': True,\n",
       " 'recommended_links': [{'url': 'https://teatrdramatyczny.pl/repertuar',\n",
       "   'confidence': 0.95},\n",
       "  {'url': 'https://teatrdramatyczny.pl/plany-repertuarowe-na-sezon-202425',\n",
       "   'confidence': 0.7}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_repertoire_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_repertoire_page': True,\n",
       " 'recommended_links': [{'url': 'https://teatrdramatyczny.pl/whats-on',\n",
       "   'confidence': 0.95}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://teatrdramatyczny.pl/whats-on\"\n",
    "content = clean_html_for_llm(url)\n",
    "links = extract_links_from_page(content, url)\n",
    "is_repertoire_page = identify_page_and_get_repertoire_links(content, links, model)\n",
    "is_repertoire_page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
