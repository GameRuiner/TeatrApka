{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse\n",
    "from agent import clean_html_for_llm, parse_repertoires_from_page, extract_links_from_page, identify_page_and_get_repertoire_links, get_repertoire_links\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test api connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ml/gp6bsjkn7w77hgytpxvg8gsw0000gn/T/ipykernel_14221/587578607.py:8: LangChainBetaWarning: The function `init_chat_model` is in beta. It is actively being worked on, so the API may change.\n",
      "  model = init_chat_model(\"Qwen/Qwen2.5-Coder-32B-Instruct\", model_provider=\"together\")\n"
     ]
    }
   ],
   "source": [
    "if not os.environ.get(\"TOGETHER_API_KEY\"):\n",
    "    os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass(\"Enter API key for Together AI: \")\n",
    "\n",
    "# meta-llama/Llama-3.3-70B-Instruct-Turbo-Free   inputs` tokens + `max_new_tokens` must be <= 8193\n",
    "# Qwen/Qwen2.5-Coder-32B-Instruct                inputs` tokens + `max_new_tokens` must be <= 32769\n",
    "# meta-llama/Llama-3.2-3B-Instruct-Turbo         gives extra text\n",
    "# meta-llama/Llama-4-Scout-17B-16E-Instruct\n",
    "model = init_chat_model(\"Qwen/Qwen2.5-Coder-32B-Instruct\", model_provider=\"together\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 22, 'total_tokens': 26, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen2.5-Coder-32B-Instruct', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ea974058-f35f-4ad7-92ff-a01aae5b51d6-0', usage_metadata={'input_tokens': 22, 'output_tokens': 4, 'total_tokens': 26, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\")\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI works by learning patterns from data to make predictions or decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://teatrdramatyczny.pl/\"\n",
    "content = clean_html_for_llm(url)\n",
    "links = extract_links_from_page(content, url)\n",
    "is_repertoire_page = identify_page_and_get_repertoire_links(content, links, model)\n",
    "# repertoires = parse_repertoires_from_page(content, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import extract_pure_json\n",
    "\n",
    "def parse_repertoires_from_page(html_content: str, client) -> list[dict]:\n",
    "    \"\"\"Parse the given HTML and return a JSON list of repertoire items found on the page.\"\"\"\n",
    "    system_message = \"\"\"\n",
    "        I will provide you with an HTML snippet containing information about theater performances. Extract all performances, including their titles, dates, and times, and return the result as a JSON array with the following format:\n",
    "        ```\n",
    "        [\n",
    "        {\n",
    "            \"title\": \"Performance name\",\n",
    "            \"date\": \"YYYY-MM-DD\",\n",
    "            \"time\": \"HH:MM\",\n",
    "            \"status\": \"Performance status\",\n",
    "            \"place\": \"Performance place\",\n",
    "        }\n",
    "        ]\n",
    "        ```\n",
    "        Important rules:\n",
    "        - Return ONLY valid JSON (no extra text or markdown).\n",
    "        - If you are reaching the token limit or need to stop, DO NOT cut off in the middle of a JSON object. \n",
    "        Finish the current object fully and stop after a comma (`,`) or after the closing bracket (`]`) if at the end.\n",
    "        - When continuing later, start exactly where you left off, starting with the next JSON object or the closing bracket.\n",
    "    \"\"\"\n",
    "    messages = F\"\"\"\n",
    "        {system_message}\n",
    "\n",
    "        {html_content}\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "         model=\"gemini-2.0-flash\", contents=messages\n",
    "    )\n",
    "    pure_json = extract_pure_json(response.text)\n",
    "    return pure_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theatre_name(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    domain = parsed_url.netloc\n",
    "    if domain.startswith(\"www.\"):\n",
    "        domain = domain[4:]\n",
    "    main_part = domain.rsplit('.', 1)[0]\n",
    "    return main_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing theatre teatrdramatyczny, url https://teatrdramatyczny.pl/\n",
      "Repertoire link https://teatrdramatyczny.pl/repertuar\n",
      "Parsing theatre teatr2strefa, url https://www.teatr2strefa.pl\n",
      "Repertoire link https://www.teatr2strefa.pl\n",
      "Parsing theatre teatrstudio, url https://teatrstudio.pl\n",
      "Repertoire link https://teatrstudio.pl/pl/repertuar\n"
     ]
    }
   ],
   "source": [
    "theatres = [\"https://teatrdramatyczny.pl/\", \"https://www.teatr2strefa.pl\", \"https://teatrstudio.pl\"]\n",
    "\n",
    "for theatre_url in theatres:\n",
    "    theater_name = get_theatre_name(theatre_url)\n",
    "    print(f\"Parsing theatre {theater_name}, url {theatre_url}\")\n",
    "    content = clean_html_for_llm(theatre_url)\n",
    "    links = extract_links_from_page(content, theatre_url)\n",
    "    repertoire_links = get_repertoire_links(links, model)\n",
    "\n",
    "    if len(repertoire_links) > 0:\n",
    "        first_url = repertoire_links[0]\n",
    "        if first_url[\"confidence\"] >= 0.7:\n",
    "            url = first_url['url']\n",
    "        else:\n",
    "            url = theatre_url\n",
    "        print(f\"Repertoire link {url}\")\n",
    "        content = clean_html_for_llm(url)   \n",
    "        performances = parse_repertoires_from_page(content, client)\n",
    "        with open(f\"temp/{theater_name}.json\", \"w\") as file:\n",
    "            file.write(performances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
